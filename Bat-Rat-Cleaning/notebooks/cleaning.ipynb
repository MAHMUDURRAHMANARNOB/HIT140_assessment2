{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f78ba8e",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1a19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2613ff7",
   "metadata": {},
   "source": [
    "File paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b51dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT1 = \"../data/dataset1.csv\"\n",
    "INPUT2 = \"../data/dataset2.csv\"\n",
    "OUT1 = \"../data/clean_dataset1.csv\"\n",
    "OUT2 = \"../data/clean_dataset2.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8238d4d",
   "metadata": {},
   "source": [
    "safe read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bd6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_read_csv(path):\n",
    "    \"\"\"Read CSV robustly and return dataframe. If file missing, raise helpful error.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Input file not found: {path}\")\n",
    "    return pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04501aa3",
   "metadata": {},
   "source": [
    "Load raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97690800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shapes: dataset1: (907, 12) dataset2: (2123, 7)\n"
     ]
    }
   ],
   "source": [
    "df1 = safe_read_csv(INPUT1)\n",
    "df2 = safe_read_csv(INPUT2)\n",
    "print(\"Raw shapes:\", \"dataset1:\", df1.shape, \"dataset2:\", df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be81225",
   "metadata": {},
   "source": [
    "Remove fully-empty rows\n",
    "Reason: trailing blank rows or placeholder rows can create many NaNs.\n",
    "Use dropna(how='all') so we keep rows with any useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c04528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping fully-empty rows: dataset1: (907, 12) dataset2: (2123, 7)\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.dropna(how=\"all\").reset_index(drop=True)\n",
    "df2 = df2.dropna(how=\"all\").reset_index(drop=True)\n",
    "print(\"After dropping fully-empty rows:\", \"dataset1:\", df1.shape, \"dataset2:\", df2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b94dd",
   "metadata": {},
   "source": [
    "Handle missing values\n",
    "Numeric → fill with median (robust to outliers)\n",
    "Categorical/text → fill with \"unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a10f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df1.select_dtypes(include=[\"float64\", \"int64\"]).columns:\n",
    "    df1[col] = df1[col].fillna(df1[col].median())\n",
    "\n",
    "for col in df1.select_dtypes(include=[\"object\"]).columns:\n",
    "    df1[col] = df1[col].fillna(\"unknown\")\n",
    "\n",
    "for col in df2.select_dtypes(include=[\"float64\", \"int64\"]).columns:\n",
    "    df2[col] = df2[col].fillna(df2[col].median())\n",
    "\n",
    "for col in df2.select_dtypes(include=[\"object\"]).columns:\n",
    "    df2[col] = df2[col].fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32c4e8d",
   "metadata": {},
   "source": [
    "Parse datetime columns\n",
    "Important: data appears in day-first format (DD/MM/YYYY HH:MM) -> use dayfirst=True\n",
    "We'll keep both original and parsed columns (suffix _parsed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5440cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cols_df1 = [\"start_time\", \"rat_period_start\", \"rat_period_end\", \"sunset_time\"]\n",
    "for col in time_cols_df1:\n",
    "    if col in df1.columns:\n",
    "        df1[col + \"_parsed\"] = pd.to_datetime(df1[col], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "if \"time\" in df2.columns:\n",
    "    df2[\"time_parsed\"] = pd.to_datetime(df2[\"time\"], dayfirst=True, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3876a1d4",
   "metadata": {},
   "source": [
    "Convert numeric columns safely\n",
    "Coerce non-numeric strings to NaN so we can handle them consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51042465",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols_df1 = [\"bat_landing_to_food\", \"seconds_after_rat_arrival\", \"risk\", \"reward\", \"month\", \"hours_after_sunset\"]\n",
    "for c in num_cols_df1:\n",
    "    if c in df1.columns:\n",
    "        df1[c] = pd.to_numeric(df1[c], errors=\"coerce\")\n",
    "\n",
    "num_cols_df2 = [\"month\", \"hours_after_sunset\", \"bat_landing_number\", \"food_availability\", \"rat_minutes\", \"rat_arrival_number\"]\n",
    "for c in num_cols_df2:\n",
    "    if c in df2.columns:\n",
    "        df2[c] = pd.to_numeric(df2[c], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a19664",
   "metadata": {},
   "source": [
    "Check outliers\n",
    "Example: negative values in hours_after_sunset may mean \"before sunset\"\n",
    "We don’t delete them, just flag them for later inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b32d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"hours_after_sunset\" in df1.columns:\n",
    "    df1[\"hours_after_sunset_outlier\"] = df1[\"hours_after_sunset\"] < 0\n",
    "\n",
    "if \"hours_after_sunset\" in df2.columns:\n",
    "    df2[\"hours_after_sunset_outlier\"] = df2[\"hours_after_sunset\"] < 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da826264",
   "metadata": {},
   "source": [
    "Clean textual/categorical columns (habit)\n",
    "Normalize text, strip whitespace, lower-case to reduce category proliferation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6f10d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"habit\" in df1.columns:\n",
    "    df1[\"habit_clean\"] = df1[\"habit\"].astype(str).str.strip().str.lower()\n",
    "    df1.loc[df1[\"habit_clean\"].isin([\"nan\", \"none\", \"none.\"]), \"habit_clean\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4d725",
   "metadata": {},
   "source": [
    "Standardize months & seasons\n",
    "Use meteorological seasons mapping (DJF, MAM, JJA, SON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d83578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_map = {\n",
    "    12: \"winter\", 1: \"winter\", 2: \"winter\",\n",
    "    3: \"spring\", 4: \"spring\", 5: \"spring\",\n",
    "    6: \"summer\", 7: \"summer\", 8: \"summer\",\n",
    "    9: \"autumn\", 10: \"autumn\", 11: \"autumn\"\n",
    "}\n",
    "\n",
    "if \"start_time_parsed\" in df1.columns:\n",
    "    df1[\"month_inferred\"] = df1[\"start_time_parsed\"].dt.month\n",
    "    df1[\"season_inferred\"] = df1[\"month_inferred\"].map(season_map)\n",
    "\n",
    "if \"time_parsed\" in df2.columns:\n",
    "    df2[\"month_inferred\"] = df2[\"time_parsed\"].dt.month\n",
    "    df2[\"season_inferred\"] = df2[\"month_inferred\"].map(season_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66ed7b2",
   "metadata": {},
   "source": [
    "Validate/derive time-based measures\n",
    "Example: for dataset1, compare recorded seconds_after_rat_arrival with computed difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0711953",
   "metadata": {},
   "outputs": [],
   "source": [
    "if {\"start_time_parsed\", \"rat_period_start_parsed\"}.issubset(df1.columns):\n",
    "    df1[\"sec_from_ratstart_calc\"] = (\n",
    "        df1[\"start_time_parsed\"] - df1[\"rat_period_start_parsed\"]\n",
    "    ).dt.total_seconds()\n",
    "    df1[\"sec_mismatch\"] = df1[\"sec_from_ratstart_calc\"] - df1[\"seconds_after_rat_arrival\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cafd596",
   "metadata": {},
   "source": [
    "Convert boolean/binary flags to safe dtypes\n",
    "Use pandas nullable integer dtype (Int64) to preserve NaNs if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "130ffba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"risk\", \"reward\"]:\n",
    "    if col in df1.columns:\n",
    "        df1[col] = df1[col].astype(\"Int64\")\n",
    "\n",
    "for col in [\"rat_arrival_number\", \"bat_landing_number\"]:\n",
    "    if col in df2.columns:\n",
    "        df2[col] = df2[col].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec610faa",
   "metadata": {},
   "source": [
    "Remove duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aed46c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.drop_duplicates().reset_index(drop=True)\n",
    "df2 = df2.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18ef5a7",
   "metadata": {},
   "source": [
    " Example safe imputation (documented & conservative)\n",
    "If rat_minutes == 0 and rat_arrival_number is NaN -> set arrivals = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "925aefa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df2[\"rat_minutes\"].notna()) & (df2[\"rat_minutes\"] == 0) & (df2[\"rat_arrival_number\"].isna())\n",
    "if mask.any():\n",
    "    df2.loc[mask, \"rat_arrival_number\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11f222",
   "metadata": {},
   "source": [
    "Save cleaned outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cadb2744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(OUT1, index=False)\n",
    "df2.to_csv(OUT2, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7817f",
   "metadata": {},
   "source": [
    " Short summary printouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4477d064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEANED dataset1 shape: (906, 22)\n",
      "CLEANED dataset2 shape: (2123, 11)\n",
      "\n",
      "Missing per column (dataset1):\n",
      " start_time                    0\n",
      "bat_landing_to_food           0\n",
      "habit                         0\n",
      "rat_period_start              0\n",
      "rat_period_end                0\n",
      "seconds_after_rat_arrival     0\n",
      "risk                          0\n",
      "reward                        0\n",
      "month                         0\n",
      "sunset_time                   0\n",
      "hours_after_sunset            0\n",
      "season                        0\n",
      "start_time_parsed             0\n",
      "rat_period_start_parsed       0\n",
      "rat_period_end_parsed         0\n",
      "sunset_time_parsed            0\n",
      "hours_after_sunset_outlier    0\n",
      "habit_clean                   0\n",
      "month_inferred                0\n",
      "season_inferred               0\n",
      "sec_from_ratstart_calc        0\n",
      "sec_mismatch                  0\n",
      "dtype: int64\n",
      "\n",
      "Missing per column (dataset2):\n",
      " time                          0\n",
      "month                         0\n",
      "hours_after_sunset            0\n",
      "bat_landing_number            0\n",
      "food_availability             0\n",
      "rat_minutes                   0\n",
      "rat_arrival_number            0\n",
      "time_parsed                   0\n",
      "hours_after_sunset_outlier    0\n",
      "month_inferred                0\n",
      "season_inferred               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"CLEANED dataset1 shape:\", df1.shape)\n",
    "print(\"CLEANED dataset2 shape:\", df2.shape)\n",
    "print(\"\\nMissing per column (dataset1):\\n\", df1.isna().sum())\n",
    "print(\"\\nMissing per column (dataset2):\\n\", df2.isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
